{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting retraction reasons with the OpenAI API\n",
    "\n",
    "Proof of concept\n",
    "\n",
    "TODO: evaluate model performance, select a model (considering pricing too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/javier/miniconda3/lib/python3.9/site-packages (0.27.6)\n",
      "Requirement already satisfied: tqdm in /home/javier/miniconda3/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in /home/javier/miniconda3/lib/python3.9/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: aiohttp in /home/javier/miniconda3/lib/python3.9/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/javier/miniconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/javier/miniconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/javier/miniconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/javier/miniconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/javier/miniconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/javier/miniconda3/lib/python3.9/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/javier/miniconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/javier/miniconda3/lib/python3.9/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/javier/miniconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/javier/miniconda3/lib/python3.9/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"text-davinci-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../../data/ePMC/retracts.json\"\n",
    "with open(filepath, 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "retrieved = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assets/openAI_key.txt', 'r') as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'invalid results': [], 'plagiarism': [], 'conflict of interest, legal reasons': [], 'research misconduct and data manipulation': [], 'agreement by author(s)': [], 'reader concerns': [], 'issues with authorship': [], 'duplicated paper': [], 'could not reproduce results': []}\n"
     ]
    }
   ],
   "source": [
    "# Define the list of retraction notices\n",
    "notices = [\n",
    "    \"invalid results\",\n",
    "    \"plagiarism\",\n",
    "    \"conflict of interest, legal reasons\",\n",
    "    \"research misconduct and data manipulation\",\n",
    "    \"agreement by author(s)\",\n",
    "    \"reader concerns\",\n",
    "    \"issues with authorship\",\n",
    "    \"duplicated paper\",\n",
    "    \"could not reproduce results\",\n",
    "] \n",
    "\n",
    "# Define a dictionary to store the results\n",
    "results = {reason:[] for reason in notices}\n",
    "\n",
    "# Define the prompt to extract retraction reasons\n",
    "reasons_string = \"\\n-\".join(results.keys())\n",
    "reason_prompt = f\"Given a list of possible reasons for retraction, please extract the reason(s) for retraction from a given text and return a comma-separated string of the identified reasons. The list of possible reasons is as follows: \\n-{reasons_string} \\nFor example, if the input text is: \\\"The article is suspected to contain manipulated data (...) The authors agreed to retract the article.\\\", the output should be \\\"research misconduct and data manipulation, agreement by author(s)\\\". There must not be any sentence in the output phrased differently than the provided retraction reason list.\"\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop over the retraction notices and request an OpenAI model its retraction reason(s)\n",
    "def get_openAI_retraction(data, model, i=10):\n",
    "    tokens = 0\n",
    "    llm_reasons_unfiltered = {}\n",
    "    llm_reasons_filtered = {}\n",
    "    for index, row in data.iterrows(): \n",
    "        i+=1\n",
    "        if i<10: #limit to 10 to keep it cheap for now\n",
    "            notice = row[\"fullText\"]\n",
    "            #print(notice)\n",
    "            #id = \n",
    "            word_count = len(notice.split())\n",
    "            tokens += word_count\n",
    "            #print(f\"Article with identifier {id} has a length of {word_count}  characters, approximately {word_count*1000/750} tokens. ~{tokens}    tokens used so far\")\n",
    "            reason_text = reason_prompt + \" \" + notice\n",
    "            reason_result = openai.Completion.create(\n",
    "                model=model,\n",
    "                prompt=reason_text,\n",
    "                max_tokens=1024,\n",
    "                stop=None,\n",
    "                temperature=0.0,# As deterministic as possible\n",
    "            )\n",
    "            reasons_string = reason_result[\"choices\"][0][\"text\"].strip()\n",
    "            #print(reasons_string)\n",
    "            reasons_filtered = []\n",
    "            for reason in notices: \n",
    "                if reason in reasons_string:\n",
    "                    reasons_filtered.append(reason)\n",
    "\n",
    "            llm_reasons_unfiltered[id] = reasons_string.split(\", \")\n",
    "            llm_reasons_filtered[id] = reasons_filtered\n",
    "            data.at[index, \"llm-reason\"] = \", \".join(reasons_filtered)\n",
    "    return data\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "davinci_one = get_openAI_retraction(retrieved, \"text-davinci-001\").dropna()\n",
    "davinci_two = get_openAI_retraction(retrieved, \"text-davinci-002\").dropna()\n",
    "davinci_three = get_openAI_retraction(retrieved, \"text-davinci-003\").dropna()\n",
    "curie_one = get_openAI_retraction(retrieved, \"text-curie-001\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_data = {}\n",
    "models = [\"text-davinci-001\", \"text-davinci-002\", \"text-davinci-003\", \"text-curie-001\"]\n",
    "for i in range(0,8):\n",
    "    row = {}\n",
    "    id = retrieved.loc[retrieved.index[i], 'source'] + retrieved.loc[retrieved.index[i], 'id']\n",
    "    row[\"fullText\"] = retrieved.loc[retrieved.index[i],'fullText']\n",
    "    row[\"text-davinci-001\"] = davinci_one.loc[davinci_one.index[i], \"llm-reason\"]\n",
    "    row[\"text-davinci-002\"] = davinci_two.loc[davinci_two.index[i], \"llm-reason\"]\n",
    "    row[\"text-davinci-003\"] = davinci_three.loc[davinci_three.index[i], \"llm-reason\"]\n",
    "    row[\"text-curie-001\"] = curie_one.loc[curie_one.index[i], \"llm-reason\"]\n",
    "    see_data[id] = row\n",
    "\n",
    "\n",
    "llm_summary = pd.DataFrame.from_dict(see_data).transpose()\n",
    "llm_summary.to_csv(\"test_llm.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "267a425285626f162e8dbac0e72a3103fc15fe1856529c1140c5b196b5352764"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
